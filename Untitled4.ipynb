{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUWOhAfT6WVN57r3vk5Pnk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import pytesseract\n","from flask import Flask, request, jsonify\n","from tensorflow.keras import layers, models\n","\n","# Set the path for Tesseract OCR\n","pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path\n","\n","# Step 1: Data Preprocessing\n","def preprocess_image(C:\\Users\\gowta\\OneDrive\\Documents\\img.jpg):\n","    # Load the image\n","    image = cv2.imread(C:\\Users\\gowta\\OneDrive\\Documents\\img.jpg)\n","    if image is None:\n","        raise ValueError(\"Image not found or unable to load.\")\n","\n","    # Resize the image\n","    image = cv2.resize(image, (300, 300))\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Gaussian blur\n","    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","    # Thresholding\n","    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","    return thresh\n","\n","def extract_text(image_path):\n","    # Preprocess the image\n","    processed_image = preprocess_image(image_path)\n","\n","    # Use Tesseract to extract text\n","    text = pytesseract.image_to_string(processed_image)\n","    return text\n","\n","# Step 2: Model Development\n","def create_model():\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 1)))  # Grayscale input\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes of medicines\n","\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","# Step 3: Flask API for Integration\n","app = Flask(__name__)\n","\n","# Load your trained model (make sure to train and save it before running this)\n","model = create_model()  # Replace with model loading if you have a pre-trained model\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    if 'file' not in request.files:\n","        return jsonify({'error': 'No file provided'}), 400\n","\n","    file = request.files['file']\n","    # Save the uploaded file temporarily\n","    file_path = 'temp_image.jpg'\n","    file.save(file_path)\n","\n","    # Preprocess the image for prediction\n","    processed_image = preprocess_image(file_path)\n","    processed_image = np.expand_dims(processed_image, axis=0)  # Add batch dimension\n","    processed_image = np.expand_dims(processed_image, axis=-1)  # Add channel dimension\n","\n","    # Make predictions\n","    prediction = model.predict(processed_image)\n","    predicted_class = np.argmax(prediction, axis=1)\n","\n","    # Extract text from the image\n","    extracted_text = extract_text(file_path)\n","\n","    os.remove(file_path)\n","\n","    return jsonify({\n","        'predicted_class': int(predicted_class[0]),\n","        'extracted_text': extracted_text\n","    })\n","\n","if __name__ == '__main__':\n","    app.run(debug=True)"],"metadata":{"id":"UXLbJss3TvQI"},"execution_count":null,"outputs":[]}]}